import sys
import os
import asyncio
import json
import threading
import time
import argparse
from pathlib import Path
from datetime import datetime, timedelta
import random

# WebSocket y HTTP server
try:
    import websockets
    from aiohttp import web
    WS_AVAILABLE = True
except ImportError:
    print("[MONITOR] Warning: websockets or aiohttp not installed. Run: pip install websockets aiohttp")
    WS_AVAILABLE = False

# Kafka imports
from kafka import KafkaProducer, KafkaConsumer

# A√±adir el directorio padre al path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from network_config import MONITOR_CONFIG, KAFKA_BROKER as KAFKA_BROKER_DEFAULT, KAFKA_TOPICS
from event_utils import generate_message_id, current_timestamp
# ‚ö†Ô∏è ARQUITECTURA: El Monitor NO accede directamente a la BD
# Toda la informaci√≥n del CP se obtiene de Central v√≠a Kafka/eventos

# Configuraci√≥n desde network_config o variables de entorno (Docker)
KAFKA_BROKER = os.environ.get('KAFKA_BROKER', KAFKA_BROKER_DEFAULT)
KAFKA_TOPICS_CONSUME = [KAFKA_TOPICS['cp_events'], KAFKA_TOPICS['central_events']]
KAFKA_TOPIC_PRODUCE = KAFKA_TOPICS['monitor_events']

# ============================================================================
# ARQUITECTURA CORRECTA: 1 Monitor por 1 Engine (relaci√≥n 1:1)
# ============================================================================
# Estas variables se setean desde argumentos de l√≠nea de comandos
MONITORED_CP_ID = None  # ID del CP que este Monitor supervisa (ej: CP_001)
ENGINE_HOST = 'localhost'  # Host del Engine
ENGINE_PORT = 5100  # Puerto TCP del Engine
SERVER_PORT = 5500  # Puerto del dashboard de este Monitor

# Estado global compartido
class SharedState:
    def __init__(self):
        self.connected_clients = set()
        self.cp_metrics = {}  # M√©tricas del CP monitoreado
        self.cp_info = {}  # ‚ö†Ô∏è Informaci√≥n del CP recibida de Central v√≠a Kafka (no de BD)
        self.alerts = []
        self.health_status = {  # Estado del health check del Engine
            'consecutive_failures': 0,
            'last_check': None,
            'last_status': 'UNKNOWN'
        }
        self.tcp_monitor_task = None  # Task de monitoreo TCP
        self.lock = threading.Lock()

shared_state = SharedState()

class EV_MonitorWS:
    """
    Monitor dedicado a supervisar UN √öNICO Engine.
    
    ARQUITECTURA CORRECTA:
    - 1 Monitor ‚Üî 1 Engine (relaci√≥n 1:1)
    - Cada CP tiene su propio par Engine+Monitor
    - El Monitor NO supervisa m√∫ltiples CPs
    """
    
    def __init__(self, cp_id, engine_host='localhost', engine_port=5100, kafka_broker='localhost:9092'):
        self.cp_id = cp_id
        self.engine_host = engine_host
        self.engine_port = engine_port
        self.kafka_broker = kafka_broker
        self.producer = None
        self._authenticated = False  # Flag para evitar re-autenticaci√≥n
        
        print(f"\n{'='*80}")
        print(f"  üè• EV MONITOR - Supervising {self.cp_id}")
        print(f"{'='*80}")
        print(f"  Monitored CP:    {self.cp_id}")
        print(f"  Engine Host:     {self.engine_host}")
        print(f"  Engine Port:     {self.engine_port}")
        print(f"  Dashboard Port:  {SERVER_PORT}")
        print(f"{'='*80}\n")
        
        self.initialize_kafka()
        self.authenticate_with_central()  # Solo se ejecuta una vez
        self.initialize_metrics()

    def initialize_kafka(self, max_retries=10):
        """Inicializa el productor de Kafka con reintentos"""
        print(f"[MONITOR-{self.cp_id}] üîå Connecting to Kafka at {self.kafka_broker}...")
        for attempt in range(max_retries):
            try:
                # Producer sin api_version expl√≠cito (auto-detecci√≥n)
                self.producer = KafkaProducer(
                    bootstrap_servers=self.kafka_broker,
                    value_serializer=lambda v: json.dumps(v).encode('utf-8'),
                    request_timeout_ms=30000,
                    retries=3,
                    acks='all'
                )
                # Intentar enviar un mensaje de prueba para verificar la conexi√≥n
                self.producer.send(KAFKA_TOPIC_PRODUCE, {'test': 'connection'})
                self.producer.flush(timeout=5)
                print(f"[MONITOR-{self.cp_id}] ‚úÖ Kafka producer initialized and connected")
                return
            except Exception as e:
                print(f"[MONITOR-{self.cp_id}] ‚ö†Ô∏è  Attempt {attempt+1}/{max_retries} - Kafka connection failed: {e}")
                if attempt < max_retries - 1:
                    time.sleep(2)
                    continue
                else:
                    print(f"[MONITOR-{self.cp_id}] ‚ùå Failed to connect to Kafka after {max_retries} attempts")
                    print(f"[MONITOR-{self.cp_id}] üí° Tip: Verificar que Kafka est√° corriendo y accesible en {self.kafka_broker}")
                    self.producer = None

    def authenticate_with_central(self):
        """
        Se conecta a EV_Central para autenticarse y validar que el Monitor
        est√° operativo y preparado para prestar servicios.
        
        Requisito del PDF: Al arrancar, el Monitor debe conectarse a Central
        para autenticarse y validar que est√° operativo.
        
        Solo se autentica UNA VEZ al iniciar.
        """
        # ‚ö†Ô∏è PROTECCI√ìN: Solo autenticarse una vez
        if hasattr(self, '_authenticated') and self._authenticated:
            print(f"[MONITOR-{self.cp_id}] ‚ö†Ô∏è Already authenticated, skipping")
            return
        
        print(f"[MONITOR-{self.cp_id}] üîê Authenticating with Central...")
        
        # Esperar a que Kafka est√© disponible si es necesario
        if not self.producer:
            print(f"[MONITOR-{self.cp_id}] ‚ö†Ô∏è  Kafka producer not initialized, retrying...")
            self.initialize_kafka(max_retries=5)
        
        if not self.producer:
            print(f"[MONITOR-{self.cp_id}] ‚ùå Cannot authenticate: Kafka not available")
            print(f"[MONITOR-{self.cp_id}] üí° Verificar:")
            print(f"[MONITOR-{self.cp_id}]    1. Kafka est√° corriendo en {self.kafka_broker}")
            print(f"[MONITOR-{self.cp_id}]    2. Red Docker correcta (ev-network)")
            print(f"[MONITOR-{self.cp_id}]    3. Nombre 'broker' se resuelve correctamente")
            return
        
        try:
            # Marcar como autenticado ANTES de enviar (para evitar re-env√≠o si falla el env√≠o)
            self._authenticated = True
            
            # Enviar mensaje de autenticaci√≥n a Central v√≠a Kafka (solo una vez)
            auth_event = {
                'message_id': generate_message_id(),
                'event_type': 'MONITOR_AUTH',
                'action': 'authenticate',
                'cp_id': self.cp_id,
                'monitor_id': f'MONITOR-{self.cp_id}',
                'engine_host': self.engine_host,
                'engine_port': self.engine_port,
                'status': 'READY',
                'timestamp': current_timestamp()
            }
            
            print(f"[MONITOR-{self.cp_id}] üì§ Sending authentication event to topic '{KAFKA_TOPIC_PRODUCE}'...")
            future = self.producer.send(KAFKA_TOPIC_PRODUCE, auth_event)
            # Esperar confirmaci√≥n del env√≠o
            record_metadata = future.get(timeout=10)
            self.producer.flush(timeout=5)
            print(f"[MONITOR-{self.cp_id}] ‚úÖ Authentication sent to Central (topic: {record_metadata.topic}, partition: {record_metadata.partition})")
            print(f"[MONITOR-{self.cp_id}] ‚úÖ Monitor validated and ready to monitor {self.cp_id}")
        except Exception as e:
            print(f"[MONITOR-{self.cp_id}] ‚ùå Authentication failed: {e}")
            import traceback
            traceback.print_exc()
            # Si falla, permitir reintentar
            self._authenticated = False

    def initialize_metrics(self):
        """Inicializa m√©tricas simuladas para el CP monitoreado"""
        shared_state.cp_metrics[self.cp_id] = {
            'temperature': 25.0,
            'efficiency': 100.0,
            'uptime_start': time.time(),
            'sessions_today': 0,
            'current_power': 0.0
        }
        print(f"[MONITOR-{self.cp_id}] üìä Metrics initialized for {self.cp_id}")

    def get_monitor_data(self):
        """
        Obtiene datos del CP monitoreado para el dashboard
        
        ‚ö†Ô∏è ARQUITECTURA: El Monitor NO accede directamente a la BD
        Toda la informaci√≥n del CP se obtiene de Central v√≠a Kafka/eventos
        y se almacena en shared_state.cp_info
        """
        try:
            # ========================================================================
            # Obtener informaci√≥n del CP desde estado local (recibida de Central)
            # NO acceder a la BD directamente
            # ========================================================================
            with shared_state.lock:
                cp = shared_state.cp_info.get(self.cp_id, {})
            
            # Si no hay informaci√≥n del CP, usar valores por defecto
            if not cp:
                # Informaci√≥n por defecto hasta que Central env√≠e datos reales
                cp = {
                    'cp_id': self.cp_id,
                    'location': 'Unknown',
                    'max_power_kw': 22.0,
                    'tariff_per_kwh': 0.30,
                    'status': 'offline',
                    'estado': 'offline'
                }
            
            # Obtener m√©tricas simuladas
            metrics = shared_state.cp_metrics.get(self.cp_id, {})
            
            # Calcular uptime
            uptime_seconds = time.time() - metrics.get('uptime_start', time.time())
            hours = int(uptime_seconds // 3600)
            minutes = int((uptime_seconds % 3600) // 60)
            uptime = f"{hours}h {minutes}m"
            
            # Determinar potencia actual basada en estado
            current_power = 0.0
            max_power = cp.get('max_power_kw') or cp.get('max_kw', 22.0)
            # Manejar tanto 'status' como 'estado'
            # ‚ö†Ô∏è Normalizar estado para asegurar que sea un estado v√°lido del CP
            raw_status = cp.get('status') or cp.get('estado', 'offline')
            valid_statuses = ['available', 'charging', 'offline', 'fault', 'out_of_service']
            if raw_status:
                raw_status_lower = raw_status.lower().strip()
                if raw_status_lower in valid_statuses:
                    cp_status = raw_status_lower
                else:
                    # Estado inv√°lido, usar 'offline' por defecto
                    print(f"[MONITOR-{self.cp_id}] ‚ö†Ô∏è Estado inv√°lido en get_monitor_data: '{raw_status}', usando 'offline'")
                    cp_status = 'offline'
            else:
                cp_status = 'offline'
            
            if cp_status == 'charging':
                current_power = max_power * random.uniform(0.85, 0.95)
            
            # Extraer datos del cp (que viene de shared_state.cp_info)
            location = cp.get('location') or cp.get('localizacion') or 'Unknown'
            if not location or location.strip() == '':
                location = 'Unknown'
            
            tariff = cp.get('tariff_per_kwh') or cp.get('tarifa_kwh') or 0.30
            
            # Construir datos del CP monitoreado para el frontend
            charging_point = {
                'cp_id': cp.get('cp_id', self.cp_id),
                'location': location,
                'power_output': max_power,
                'tariff': tariff,
                'status': cp_status,
                'temperature': metrics.get('temperature', 25.0),
                'efficiency': metrics.get('efficiency', 100.0),
                'uptime': uptime,
                'sessions_today': metrics.get('sessions_today', 0),
                'current_power': round(current_power, 1)
            }
            
            # Obtener alertas recientes
            alerts = shared_state.alerts[-50:]  # √öltimas 50 alertas
            
            return {
                'charging_point': charging_point,
                'alerts': alerts,
                'health_status': shared_state.health_status
            }
            
        except Exception as e:
            print(f"[MONITOR-{self.cp_id}] ‚ùå Error getting monitor data: {e}")
            import traceback
            traceback.print_exc()
            return {
                'charging_point': None,
                'alerts': [],
                'health_status': shared_state.health_status
            }

    def get_usage_stats(self):
        """Genera estad√≠sticas de uso de los √∫ltimos d√≠as"""
        # Simular datos de uso para el gr√°fico
        stats = []
        labels = ['Lun', 'Mar', 'Mi√©', 'Jue', 'Vie', 'S√°b', 'Dom']
        
        for label in labels:
            # Generar valor aleatorio entre 5 y 20 sesiones
            value = random.randint(5, 20)
            stats.append({
                'label': label,
                'value': value
            })
        
        return stats

    def add_alert(self, level, message):
        """A√±ade una alerta al sistema"""
        alert = {
            'level': level,  # 'critical', 'warning', 'info', 'success'
            'message': message,
            'timestamp': datetime.now().isoformat()
        }
        
        with shared_state.lock:
            shared_state.alerts.append(alert)
            # Mantener solo las √∫ltimas 50 alertas
            if len(shared_state.alerts) > 50:
                shared_state.alerts = shared_state.alerts[-50:]
        
        return alert

    def simulate_metrics_update(self):
        """Simula actualizaci√≥n de m√©tricas de los CPs"""
        with shared_state.lock:
            for cp_id, metrics in shared_state.cp_metrics.items():
                # Simular variaci√≥n de temperatura (23-28¬∞C)
                metrics['temperature'] += random.uniform(-0.5, 0.5)
                metrics['temperature'] = max(23, min(28, metrics['temperature']))
                
                # Simular eficiencia (95-100%)
                metrics['efficiency'] += random.uniform(-1, 1)
                metrics['efficiency'] = max(95, min(100, metrics['efficiency']))

# Instancia global del monitor (se inicializa en main despu√©s de parsear argumentos)
monitor_instance = None

def get_local_ip():
    """Obtiene la IP local del sistema"""
    import socket
    try:
        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        s.connect(("8.8.8.8", 80))
        local_ip = s.getsockname()[0]
        s.close()
        return local_ip
    except Exception:
        return "localhost"

async def websocket_handler(websocket, path):
    """Maneja conexiones WebSocket de la interfaz web"""
    shared_state.connected_clients.add(websocket)
    print(f"[WS] üîå New monitor client connected. Total clients: {len(shared_state.connected_clients)}")
    
    try:
        async for message in websocket:
            data = json.loads(message)
            msg_type = data.get('type')
            
            if msg_type == 'get_monitor_data':
                # Enviar datos del monitor
                monitor_data = monitor_instance.get_monitor_data()
                await websocket.send(json.dumps({
                    'type': 'monitor_data',
                    'data': monitor_data
                }))
                    
    except websockets.exceptions.ConnectionClosed:
        pass
    except Exception as e:
        print(f"[WS] ‚ùå Error handling websocket message: {e}")
    finally:
        shared_state.connected_clients.remove(websocket)

async def websocket_handler_http(request):
    """Manejador de WebSocket para aiohttp"""
    ws = web.WebSocketResponse()
    await ws.prepare(request)
    
    client_id = id(ws)
    shared_state.connected_clients.add(ws)
    print(f"[WS] Connected client {client_id}. Total: {len(shared_state.connected_clients)}")
    
    try:
        # Escuchar mensajes del cliente
        async for msg in ws:
            if msg.type == web.WSMsgType.TEXT:
                try:
                    data = json.loads(msg.data)
                    msg_type = data.get('type')
                    
                    if msg_type == 'get_monitor_data':
                        # Enviar datos del monitor
                        monitor_data = monitor_instance.get_monitor_data()
                        await ws.send_str(json.dumps({
                            'type': 'monitor_data',
                            'data': monitor_data
                        }))
                        
                except json.JSONDecodeError:
                    print(f"[WS] Invalid JSON from {client_id}")
            elif msg.type == web.WSMsgType.ERROR:
                print(f"[WS] WebSocket error: {ws.exception()}")
                
    except Exception as e:
        print(f"[WS] Error with client {client_id}: {e}")
    finally:
        shared_state.connected_clients.discard(ws)
        print(f"[WS] Disconnected client {client_id}. Total: {len(shared_state.connected_clients)}")
    
    return ws

async def serve_dashboard(request):
    """Sirve el archivo monitor_dashboard.html"""
    dashboard_path = Path(__file__).parent / 'monitor_dashboard.html'
    try:
        with open(dashboard_path, 'r', encoding='utf-8') as f:
            html_content = f.read()
        return web.Response(text=html_content, content_type='text/html')
    except FileNotFoundError:
        return web.Response(text="Monitor dashboard not found", status=404)

async def start_http_server():
    """Inicia el servidor HTTP para servir el dashboard"""
    app = web.Application()
    app.router.add_get('/', serve_dashboard)
    
    runner = web.AppRunner(app)
    await runner.setup()
    site = web.TCPSite(runner, '0.0.0.0', SERVER_PORT)
    await site.start()
    print(f"[HTTP] üåê Server started on http://0.0.0.0:{SERVER_PORT}")

async def broadcast_updates():
    """Broadcast actualizaciones peri√≥dicas a todos los clientes"""
    while True:
        await asyncio.sleep(3)  # Cada 3 segundos
        
        # Simular actualizaci√≥n de m√©tricas
        monitor_instance.simulate_metrics_update()
        
        if shared_state.connected_clients:
            monitor_data = monitor_instance.get_monitor_data()
            message = json.dumps({
                'type': 'monitor_data',
                'data': monitor_data
            })
            
            disconnected_clients = set()
            for client in shared_state.connected_clients:
                try:
                    # Compatibilidad con aiohttp WebSockets
                    if hasattr(client, 'send_str'):
                        await client.send_str(message)
                    else:
                        await client.send(message)
                except:
                    disconnected_clients.add(client)
            
            # Remover clientes desconectados
            for client in disconnected_clients:
                shared_state.connected_clients.discard(client)

async def kafka_listener():
    """Escucha eventos de Kafka y los broadcast a los clientes WebSocket"""
    loop = asyncio.get_event_loop()
    
    def consume_kafka():
        """Funci√≥n bloqueante que consume de Kafka"""
        max_retries = 10
        # Usar kafka_broker de la instancia del Monitor si est√° disponible, sino usar la variable global
        kafka_broker_to_use = monitor_instance.kafka_broker if monitor_instance else KAFKA_BROKER
        
        for attempt in range(max_retries):
            try:
                print(f"[KAFKA] üîå Connecting consumer to Kafka at {kafka_broker_to_use}...")
                print(f"[KAFKA] üìç Monitor instance: {monitor_instance.cp_id if monitor_instance else 'None'}")
                print(f"[KAFKA] üîó Using broker: {kafka_broker_to_use}")
                # Usar cp_id de monitor_instance si est√° disponible, sino usar MONITORED_CP_ID global
                cp_id_for_group = monitor_instance.cp_id if monitor_instance else MONITORED_CP_ID or 'default'
                # ‚ö†Ô∏è IMPORTANTE: Usar group_id √∫nico y auto_offset_reset='latest' para evitar leer mensajes antiguos
                import time as time_module
                unique_group_id = f'ev_monitor_ws_group_{cp_id_for_group}_{int(time_module.time())}'
                # Consumer sin api_version expl√≠cito (auto-detecci√≥n)
                consumer = KafkaConsumer(
                    *KAFKA_TOPICS_CONSUME,
                    bootstrap_servers=kafka_broker_to_use,
                    value_deserializer=lambda m: json.loads(m.decode('utf-8')),
                    auto_offset_reset='latest',  # Solo leer mensajes nuevos despu√©s de conectarse
                    group_id=unique_group_id,  # Group ID √∫nico por inicio
                    request_timeout_ms=30000,
                    session_timeout_ms=10000,
                    consumer_timeout_ms=5000
                )
                
                print(f"[KAFKA] ‚úÖ Consumer connected, listening to {KAFKA_TOPICS_CONSUME}")
                print(f"[KAFKA] üîí Consumer configured to ONLY read NEW messages (latest offset)")
                
                # ‚ö†Ô∏è CR√çTICO: Usar poll() en lugar de 'for message in consumer:' para mejor control
                # 'for message in consumer:' puede leer offsets antiguos si el group_id no es √∫nico
                while True:
                    try:
                        # Poll con timeout para procesar mensajes nuevos
                        msg_pack = consumer.poll(timeout_ms=2000, max_records=50)
                        
                        if msg_pack:
                            # Procesar mensajes recibidos
                            for topic_partition, messages in msg_pack.items():
                                for message in messages:
                                    event = message.value
                                    # Programar el procesamiento en el event loop
                                    asyncio.run_coroutine_threadsafe(
                                        process_kafka_event(event),
                                        loop
                                    )
                    except Exception as poll_error:
                        print(f"[KAFKA] ‚ö†Ô∏è Error en poll: {poll_error}")
                        import traceback
                        traceback.print_exc()
                        time.sleep(1)
                        continue
                    
            except Exception as e:
                import traceback
                print(f"[KAFKA] ‚ö†Ô∏è  Attempt {attempt+1}/{max_retries} - Consumer error: {e}")
                print(f"[KAFKA] üìã Error details: {traceback.format_exc()}")
                if attempt < max_retries - 1:
                    time.sleep(2)
                    continue
                else:
                    print(f"[KAFKA] ‚ùå Failed to connect consumer after {max_retries} attempts")
                    print(f"[KAFKA] üí° Verificar:")
                    print(f"[KAFKA]    1. Kafka est√° corriendo en {kafka_broker_to_use}")
                    print(f"[KAFKA]    2. Desde PC3, probar conectividad: telnet <IP_PC2> 9092")
                    print(f"[KAFKA]    3. Firewall permite tr√°fico en puerto 9092 de PC2")
                    print(f"[KAFKA]    4. Variable KAFKA_BROKER en .env de PC3: {kafka_broker_to_use}")
                    print(f"[KAFKA]    5. PC2_IP en .env de PC2 debe ser la IP real de PC2")
                    break
    
    # Ejecutar el consumidor de Kafka en un thread separado
    kafka_thread = threading.Thread(target=consume_kafka, daemon=True)
    kafka_thread.start()

async def process_kafka_event(event):
    """
    Procesa eventos de Kafka y genera alertas
    
    ‚ö†Ô∏è ARQUITECTURA: El Monitor recibe informaci√≥n del CP desde Central v√≠a Kafka
    y la almacena en shared_state.cp_info (NO accede a BD directamente)
    
    ‚ö†Ô∏è IMPORTANTE: Cada Monitor SOLO procesa eventos de SU CP asignado (1:1)
    """
    action = event.get('action', '')
    event_type = event.get('event_type', '')
    cp_id = event.get('cp_id') or event.get('engine_id')
    
    # ‚ö†Ô∏è CR√çTICO: Verificar monitor_instance primero
    if not monitor_instance:
        # Si no hay instancia del monitor, ignorar todos los eventos
        return
    
    # ‚ö†Ô∏è CR√çTICO: Filtrar por cp_id ANTES de cualquier otro procesamiento
    # Cada Monitor SOLO procesa eventos de SU CP asignado (relaci√≥n 1:1)
    if cp_id and cp_id != monitor_instance.cp_id:
        # Este evento es para otro CP, ignorarlo completamente
        # Solo loguear si es un evento importante para debug (opcional)
        if event_type in ['CP_INFO', 'CP_REGISTRATION']:
            print(f"[MONITOR-{monitor_instance.cp_id}] ‚ö†Ô∏è Ignorando evento de otro CP: type={event_type}, cp_id={cp_id} (este Monitor supervisa {monitor_instance.cp_id})")
        return
    
    # Si no hay cp_id en el evento, verificar si es un evento que necesitamos procesar
    # (algunos eventos no tienen cp_id pero son relevantes)
    if not cp_id and event_type not in ['MONITOR_AUTH']:
        # Evento sin cp_id que no es MONITOR_AUTH, ignorar
        return
    
    # Debug: Log solo eventos relevantes para este Monitor
    if event_type in ['CP_INFO', 'CP_REGISTRATION'] or 'cp_info' in action:
        print(f"[MONITOR-{monitor_instance.cp_id}] üì® Evento recibido: type={event_type}, action={action}, cp_id={cp_id}")
    
    # ‚ö†Ô∏è IGNORAR eventos MONITOR_AUTH (no contienen informaci√≥n del CP)
    if event_type == 'MONITOR_AUTH':
        # Este evento es solo para autenticaci√≥n, Central enviar√° CP_INFO despu√©s
        return
    
    # ‚ö†Ô∏è IGNORAR CP_REGISTRATION directos del Engine - Solo procesar CP_INFO de Central
    # CP_REGISTRATION es un evento que el Engine env√≠a a Central, no al Monitor
    # Central procesa CP_REGISTRATION y luego env√≠a CP_INFO al Monitor
    # Si procesamos CP_REGISTRATION aqu√≠, causamos bucles de actualizaciones
    if event_type == 'CP_REGISTRATION' and action == 'connect':
        print(f"[MONITOR-{monitor_instance.cp_id}] ‚ö†Ô∏è Ignorando CP_REGISTRATION directo - Central enviar√° CP_INFO despu√©s")
        return
    
    # A partir de aqu√≠, solo procesamos eventos del CP de este Monitor
    # Actualizar informaci√≥n del CP recibida de Central
    if cp_id and cp_id == monitor_instance.cp_id:
        # Este evento es para el CP que este Monitor supervisa
        with shared_state.lock:
            if cp_id not in shared_state.cp_info:
                shared_state.cp_info[cp_id] = {}
            
            # ‚ö†Ô∏è SOLO procesar CP_INFO de Central (no CP_REGISTRATION directos)
            # Central es la √∫nica fuente de verdad para la informaci√≥n del CP
            if event_type == 'CP_INFO' or action == 'cp_info_update':
                # Registro o actualizaci√≥n del CP desde Central (√∫nico con acceso a BD)
                cp_data = event.get('data', {}) if isinstance(event.get('data'), dict) else {}
                
                # Extraer datos del evento CP_INFO
                # Los datos est√°n en event.data seg√∫n la estructura que env√≠a Central
                # Pero tambi√©n pueden estar en el nivel ra√≠z como fallback
                
                # Extraer ubicaci√≥n: primero del data, luego del nivel ra√≠z del evento
                cp_location = (cp_data.get('location') or cp_data.get('localizacion') or 
                             event.get('location') or event.get('localizacion') or '')
                if not cp_location or cp_location.strip() == '':
                    cp_location = 'Unknown'
                
                # Extraer estado: primero del data, luego del nivel ra√≠z del evento
                cp_status = (cp_data.get('status') or cp_data.get('estado') or 
                           event.get('status') or event.get('estado') or 'offline')
                
                # Normalizar estado (filtrar estados inv√°lidos)
                valid_statuses = ['available', 'charging', 'offline', 'fault', 'out_of_service']
                if cp_status:
                    cp_status_lower = cp_status.lower().strip()
                    if cp_status_lower in valid_statuses:
                        cp_status = cp_status_lower
                    else:
                        # Estado inv√°lido: NO usar 'available' por defecto, mantener 'offline' o el √∫ltimo estado conocido
                        print(f"[MONITOR-{cp_id}] ‚ö†Ô∏è Estado inv√°lido recibido: '{cp_status}', manteniendo estado actual o usando 'offline'")
                        # Si ya hay un estado guardado, mantenerlo; si no, usar 'offline'
                        existing_status = shared_state.cp_info.get(cp_id, {}).get('status') or shared_state.cp_info.get(cp_id, {}).get('estado')
                        cp_status = existing_status if existing_status and existing_status.lower() in valid_statuses else 'offline'
                else:
                    cp_status = 'offline'
                
                # Extraer max_power: primero del data, luego del nivel ra√≠z del evento
                max_power = (cp_data.get('max_power_kw') or cp_data.get('max_kw') or 
                           event.get('max_power_kw') or event.get('max_kw') or 22.0)
                # Asegurar que es num√©rico
                try:
                    max_power = float(max_power) if max_power else 22.0
                    if max_power <= 0:
                        max_power = 22.0
                except (ValueError, TypeError):
                    max_power = 22.0
                
                # Extraer tariff: primero del data, luego del nivel ra√≠z del evento
                tariff = (cp_data.get('tariff_per_kwh') or cp_data.get('tarifa_kwh') or 
                         event.get('tariff_per_kwh') or event.get('tarifa_kwh') or 0.30)
                # Asegurar que es num√©rico
                try:
                    tariff = float(tariff) if tariff else 0.30
                    if tariff <= 0:
                        tariff = 0.30
                except (ValueError, TypeError):
                    tariff = 0.30
                
                # ‚ö†Ô∏è CR√çTICO: Verificar si el estado realmente cambi√≥ antes de actualizar
                # Esto previene bucles infinitos de actualizaciones innecesarias
                current_stored_status = shared_state.cp_info[cp_id].get('status') or shared_state.cp_info[cp_id].get('estado')
                current_stored_location = shared_state.cp_info[cp_id].get('location') or shared_state.cp_info[cp_id].get('localizacion')
                current_stored_max_power = shared_state.cp_info[cp_id].get('max_power_kw') or shared_state.cp_info[cp_id].get('max_kw')
                current_stored_tariff = shared_state.cp_info[cp_id].get('tariff_per_kwh') or shared_state.cp_info[cp_id].get('tarifa_kwh')
                
                # Verificar si realmente hay cambios
                status_changed = current_stored_status != cp_status
                location_changed = current_stored_location != cp_location
                max_power_changed = abs((current_stored_max_power or 0) - max_power) > 0.01
                tariff_changed = abs((current_stored_tariff or 0) - tariff) > 0.01
                
                if not (status_changed or location_changed or max_power_changed or tariff_changed):
                    # No hay cambios reales, ignorar este evento para evitar bucles
                    print(f"[MONITOR-{cp_id}] ‚ÑπÔ∏è CP_INFO sin cambios (status={cp_status}), omitiendo actualizaci√≥n para evitar bucle")
                    return
                
                print(f"[MONITOR-{cp_id}] ‚úÖ Procesando CP_INFO: status={cp_status} (cambi√≥: {status_changed}), location={cp_location}, max_power={max_power}, tariff={tariff}")
                
                # Guardar en shared_state.cp_info solo si hay cambios
                shared_state.cp_info[cp_id].update({
                    'cp_id': cp_id,
                    'location': cp_location,
                    'localizacion': cp_location,
                    'max_power_kw': max_power,
                    'max_kw': max_power,
                    'tariff_per_kwh': tariff,
                    'tarifa_kwh': tariff,
                    'status': cp_status,
                    'estado': cp_status
                })
                print(f"[MONITOR-{cp_id}] üíæ CP_INFO actualizado - status: {cp_status}")
                # No es necesario broadcast inmediato - el broadcast peri√≥dico lo har√° cada 3 segundos
                # await broadcast_monitor_data()  # Comentado para evitar saturaci√≥n
            elif ('status' in event or 'estado' in event) and event_type != 'MONITOR_AUTH' and event_type != 'CP_REGISTRATION':
                # Actualizar estado del CP (solo si no es MONITOR_AUTH o CP_REGISTRATION)
                # CP_REGISTRATION ya se maneja arriba y se ignora para evitar bucles
                new_status = event.get('status') or event.get('estado')
                
                # ‚ö†Ô∏è FILTRAR estados inv√°lidos (solo aceptar estados v√°lidos del CP)
                valid_statuses = ['available', 'charging', 'offline', 'fault', 'out_of_service']
                if new_status and new_status.lower() not in valid_statuses:
                    # Ignorar estados inv√°lidos, mantener el actual
                    return
                
                # ‚ö†Ô∏è CR√çTICO: Verificar si el estado realmente cambi√≥ antes de actualizar
                current_stored_status = shared_state.cp_info[cp_id].get('status') or shared_state.cp_info[cp_id].get('estado')
                if current_stored_status == new_status:
                    # Estado no cambi√≥, ignorar para evitar bucles
                    print(f"[MONITOR-{cp_id}] ‚ÑπÔ∏è Estado {new_status} ya est√° sincronizado, omitiendo actualizaci√≥n para evitar bucle")
                    return
                
                if new_status:
                    shared_state.cp_info[cp_id]['status'] = new_status
                    shared_state.cp_info[cp_id]['estado'] = new_status
                    print(f"[MONITOR-{cp_id}] üì• Estado actualizado desde Central: {current_stored_status} ‚Üí {new_status}")
                    # El broadcast peri√≥dico actualizar√° el dashboard autom√°ticamente
    
    # Procesar eventos de carga y errores
    # ‚ö†Ô∏è IMPORTANTE: Solo procesar si cp_id coincide con el CP de este Monitor
    # Esto es una verificaci√≥n adicional aunque ya filtramos arriba
    if cp_id and cp_id != monitor_instance.cp_id:
        # Evento para otro CP, no procesar
        return
    
    # Procesar eventos de carga y errores para el CP de este Monitor
    if action == 'charging_started':
        username = event.get('username')
        alert = monitor_instance.add_alert(
            'info',
            f"‚úÖ Carga iniciada en {cp_id} por {username}"
        )
        await broadcast_alert(alert)
        # Actualizar estado a 'charging'
        with shared_state.lock:
            if cp_id in shared_state.cp_info:
                shared_state.cp_info[cp_id]['status'] = 'charging'
                shared_state.cp_info[cp_id]['estado'] = 'charging'
        
    elif action == 'charging_stopped':
        username = event.get('username')
        energy = event.get('energy_kwh', 0)
        alert = monitor_instance.add_alert(
            'success',
            f"‚õî Carga completada en {cp_id}: {energy:.2f} kWh"
        )
        await broadcast_alert(alert)
        # Actualizar estado a 'available'
        with shared_state.lock:
            if cp_id in shared_state.cp_info:
                shared_state.cp_info[cp_id]['status'] = 'available'
                shared_state.cp_info[cp_id]['estado'] = 'available'
        
    elif action == 'fault_detected':
        alert = monitor_instance.add_alert(
            'critical',
            f"üî¥ Fallo detectado en {cp_id}"
        )
        await broadcast_alert(alert)
        # Actualizar estado a 'fault'
        with shared_state.lock:
            if cp_id in shared_state.cp_info:
                shared_state.cp_info[cp_id]['status'] = 'fault'
                shared_state.cp_info[cp_id]['estado'] = 'fault'
        
    elif action == 'cp_offline':
        alert = monitor_instance.add_alert(
            'warning',
            f"‚ö†Ô∏è {cp_id} fuera de l√≠nea"
        )
        await broadcast_alert(alert)
        # Actualizar estado a 'offline'
        with shared_state.lock:
            if cp_id in shared_state.cp_info:
                shared_state.cp_info[cp_id]['status'] = 'offline'
                shared_state.cp_info[cp_id]['estado'] = 'offline'
        
    elif action == 'cp_error_simulated':
        error_type = event.get('error_type', 'error')
        alert = monitor_instance.add_alert(
            'critical',
            f"üö® Admin simul√≥ {error_type} en {cp_id}"
        )
        await broadcast_alert(alert)
        # Actualizar estado seg√∫n tipo de error
        with shared_state.lock:
            if cp_id in shared_state.cp_info:
                if error_type == 'fault':
                    shared_state.cp_info[cp_id]['status'] = 'fault'
                elif error_type == 'out_of_service':
                    shared_state.cp_info[cp_id]['status'] = 'out_of_service'
                shared_state.cp_info[cp_id]['estado'] = shared_state.cp_info[cp_id]['status']
        # El broadcast peri√≥dico actualizar√° el dashboard autom√°ticamente
        
    elif action == 'cp_error_fixed' or action == 'resume':
        alert = monitor_instance.add_alert(
            'success',
            f"‚úÖ Admin repar√≥ {cp_id}, ahora disponible"
        )
        await broadcast_alert(alert)
        # Actualizar estado a 'available'
        with shared_state.lock:
            if cp_id in shared_state.cp_info:
                shared_state.cp_info[cp_id]['status'] = 'available'
                shared_state.cp_info[cp_id]['estado'] = 'available'
        # El broadcast peri√≥dico actualizar√° el dashboard autom√°ticamente

async def broadcast_alert(alert):
    """Broadcast una alerta a todos los clientes WebSocket"""
    if not shared_state.connected_clients:
        return
    
    message = json.dumps({
        'type': 'alert',
        'alert': alert
    })
    
    disconnected_clients = set()
    for client in shared_state.connected_clients:
        try:
            # Compatibilidad con aiohttp WebSockets
            if hasattr(client, 'send_str'):
                await client.send_str(message)
            else:
                await client.send(message)
        except:
            disconnected_clients.add(client)
    
    # Remover clientes desconectados
    for client in disconnected_clients:
        shared_state.connected_clients.discard(client)

async def broadcast_monitor_data():
    """Broadcast datos actualizados del monitor a todos los clientes"""
    if not shared_state.connected_clients:
        return
    
    monitor_data = monitor_instance.get_monitor_data()
    message = json.dumps({
        'type': 'monitor_data',
        'data': monitor_data
    })
    
    disconnected_clients = set()
    for client in shared_state.connected_clients:
        try:
            # Compatibilidad con aiohttp WebSockets
            if hasattr(client, 'send_str'):
                await client.send_str(message)
            else:
                await client.send(message)
        except:
            disconnected_clients.add(client)
    
    # Remover clientes desconectados
    for client in disconnected_clients:
        shared_state.connected_clients.discard(client)

async def tcp_health_check():
    """
    ============================================================================
    MONITOREO TCP DEL ENGINE (1:1)
    ============================================================================
    Monitoreo TCP del Engine seg√∫n especificaci√≥n del PDF.
    Env√≠a "STATUS?" cada segundo y detecta fallos.
    
    ARQUITECTURA CORRECTA:
    - Este Monitor supervisa UN SOLO Engine
    - Usa monitor_instance.cp_id, .engine_host, .engine_port
    - Reporta solo fallos de SU Engine asignado
    
    Seg√∫n PDF p√°gina 3-4:
    - Conexi√≥n TCP con el Engine
    - Env√≠o de mensajes cada segundo
    - Detecci√≥n de respuestas KO
    - Reporte a Central tras m√∫ltiples fallos
    ============================================================================
    """
    consecutive_failures = 0
    last_reported_failure = None  # Timestamp del √∫ltimo fallo reportado
    startup_grace_period = 30  # Periodo de gracia al inicio (30 segundos) para dar tiempo al Engine
    monitor_start_time = time.time()
    
    # Inicializar tracking
    shared_state.health_status = {
        'consecutive_failures': 0,
        'last_check': time.time(),
        'last_status': 'UNKNOWN'
    }
    
    print(f"[MONITOR-{monitor_instance.cp_id}] üè• Starting TCP health monitoring")
    print(f"[MONITOR-{monitor_instance.cp_id}]    Engine: {monitor_instance.engine_host}:{monitor_instance.engine_port}")
    print(f"[MONITOR-{monitor_instance.cp_id}]    Frequency: Every 1 second")
    
    # ‚ö†Ô∏è IMPORTANTE: Esperar al inicio para que el Engine est√© completamente listo
    # El Engine necesita tiempo para iniciar Kafka, registrarse y abrir el servidor TCP
    initial_wait_time = 10  # Esperar 10 segundos antes de empezar health checks
    print(f"[MONITOR-{monitor_instance.cp_id}] ‚è≥ Waiting {initial_wait_time}s for Engine to be ready...")
    await asyncio.sleep(initial_wait_time)
    print(f"[MONITOR-{monitor_instance.cp_id}] ‚úÖ Starting health checks")
    
    while True:
        try:
            await asyncio.sleep(1)  # ‚úÖ CADA 1 SEGUNDO (seg√∫n PDF)
            
            try:
                # ‚úÖ Conectar al Engine v√≠a TCP
                # Reducir logs excesivos - solo imprimir cada 10 intentos o si hay error
                # Aumentar timeout para dar m√°s tiempo a la conexi√≥n
                # print(f"[MONITOR-{monitor_instance.cp_id}] üîç Attempting to connect to {monitor_instance.engine_host}:{monitor_instance.engine_port}")
                try:
                    reader, writer = await asyncio.wait_for(
                        asyncio.open_connection(monitor_instance.engine_host, monitor_instance.engine_port),
                        timeout=3.0  # Timeout razonable para conexi√≥n TCP
                    )
                    # Solo imprimir cada 10 conexiones exitosas para reducir ruido
                    # print(f"[MONITOR-{monitor_instance.cp_id}] ‚úÖ Connected to Engine")
                except asyncio.TimeoutError:
                    # Timeout en la conexi√≥n - esto S√ç es un timeout real
                    consecutive_failures += 1
                    # Solo imprimir cada 3 fallos para reducir ruido
                    if consecutive_failures % 3 == 0 or consecutive_failures <= 3:
                        print(f"[MONITOR-{monitor_instance.cp_id}] ‚ö†Ô∏è Connection timeout (failure {consecutive_failures}/3)")
                    shared_state.health_status = {
                        'consecutive_failures': consecutive_failures,
                        'last_check': time.time(),
                        'last_status': 'TIMEOUT'
                    }
                    
                    # Si hay 3+ fallos consecutivos, reportar a Central
                    if consecutive_failures >= 3:
                        # ‚ö†Ô∏è PROTECCI√ìN: No reportar fallos durante el per√≠odo de gracia inicial (Engine puede estar iniciando)
                        time_since_start = time.time() - monitor_start_time
                        if time_since_start < startup_grace_period:
                            print(f"[MONITOR-{monitor_instance.cp_id}] ‚è≥ Monitor inici√≥ hace {time_since_start:.1f}s, esperando a que Engine est√© disponible (grace period: {startup_grace_period}s)")
                            consecutive_failures = 0  # Reset durante grace period
                            await asyncio.sleep(1)
                            continue
                        
                        # ‚ö†Ô∏è PROTECCI√ìN: No reportar el mismo fallo repetidamente (evitar bucle)
                        current_time = time.time()
                        if last_reported_failure and (current_time - last_reported_failure) < 60:  # No reportar m√°s de una vez por minuto
                            print(f"[MONITOR-{monitor_instance.cp_id}] ‚ö†Ô∏è Fallo ya reportado recientemente, esperando antes de reportar de nuevo")
                            consecutive_failures = 0  # Reset para evitar spam
                            await asyncio.sleep(5)  # Esperar m√°s tiempo antes de reintentar
                            continue
                        
                        print(f"[MONITOR-{monitor_instance.cp_id}] üö® Connection timeouts, reporting to Central")
                        if monitor_instance.producer:
                            event = {
                                'message_id': generate_message_id(),
                                'event_type': 'ENGINE_FAILURE',
                                'action': 'report_engine_failure',
                                'cp_id': monitor_instance.cp_id,
                                'failure_type': 'timeout',
                                'consecutive_failures': consecutive_failures,
                                'timestamp': current_timestamp(),
                                'monitor_id': f'MONITOR-{monitor_instance.cp_id}'
                            }
                            monitor_instance.producer.send(KAFKA_TOPIC_PRODUCE, event)
                            monitor_instance.producer.flush()
                            last_reported_failure = current_time  # Marcar que se report√≥
                            consecutive_failures = 0
                        await asyncio.sleep(5)  # Esperar m√°s tiempo antes de reintentar
                    
                    # Continuar al siguiente intento
                    continue
                
                # ‚úÖ Enviar "STATUS?"
                # Reducir logs - no imprimir cada STATUS? enviado
                writer.write(b"STATUS?\n")
                await writer.drain()
                
                # ‚úÖ Recibir respuesta - leer hasta encontrar newline o timeout
                try:
                    # Timeout razonable para respuesta TCP
                    data = await asyncio.wait_for(
                        reader.readuntil(b'\n'),  # Leer hasta encontrar newline
                        timeout=2.0  # Timeout de 2 segundos es suficiente
                    )
                    response = data.decode().strip()
                    # Solo imprimir si hay problema, no cada respuesta OK
                    if response != "OK":
                        print(f"[MONITOR-{monitor_instance.cp_id}] üì® Received: {response}")
                except asyncio.IncompleteReadError as e:
                    # Si hay datos parciales, leerlos
                    partial = e.partial
                    if partial:
                        response = partial.decode().strip()
                        print(f"[MONITOR-{monitor_instance.cp_id}] üì® Received (partial): {response}")
                    else:
                        # Intentar leer m√°s datos
                        try:
                            data = await asyncio.wait_for(
                                reader.read(100),
                                timeout=1.0
                            )
                            response = data.decode().strip()
                            print(f"[MONITOR-{monitor_instance.cp_id}] üì® Received (after partial): {response}")
                        except Exception as e2:
                            print(f"[MONITOR-{monitor_instance.cp_id}] ‚ö†Ô∏è Error reading after partial: {e2}")
                            raise asyncio.TimeoutError("Failed to read response")
                except Exception as e:
                    error_msg = str(e) if e else type(e).__name__
                    error_type = type(e).__name__
                    print(f"[MONITOR-{monitor_instance.cp_id}] ‚ö†Ô∏è Error reading response: {error_msg} (type: {error_type})")
                    
                    # Intentar recuperar datos parciales antes de contar como timeout
                    partial_data = None
                    try:
                        # Si es IncompleteReadError, tiene atributo partial
                        if hasattr(e, 'partial'):
                            partial_data = e.partial
                        elif isinstance(e, (ConnectionResetError, OSError, BrokenPipeError)):
                            # Conexi√≥n cerrada - podr√≠a haber datos en el buffer
                            # Intentar leer cualquier dato pendiente
                            try:
                                # Intentar leer con timeout corto
                                partial_data = await asyncio.wait_for(
                                    reader.read(100),
                                    timeout=0.1
                                )
                            except:
                                pass
                    except:
                        pass
                    
                    # Si tenemos datos parciales que parecen v√°lidos, usarlos
                    if partial_data:
                        try:
                            response = partial_data.decode().strip()
                            print(f"[MONITOR-{monitor_instance.cp_id}] üì® Received (partial/error): '{response}'")
                            # Si la respuesta parcial es "OK" o "KO", es v√°lida
                            if response in ['OK', 'KO']:
                                # Continuar procesando con esta respuesta
                                # NO lanzar TimeoutError - es un error de lectura pero tenemos la respuesta
                                print(f"[MONITOR-{monitor_instance.cp_id}] ‚úÖ Recovered partial response: {response}")
                                # Continuar con el procesamiento normal de la respuesta
                            else:
                                # Datos parciales no v√°lidos - timeout real
                                raise asyncio.TimeoutError(f"Failed to read response: {error_msg}")
                        except Exception as decode_error:
                            print(f"[MONITOR-{monitor_instance.cp_id}] ‚ö†Ô∏è Error decoding partial data: {decode_error}")
                            raise asyncio.TimeoutError(f"Failed to read response: {error_msg}")
                    else:
                        # No hay datos parciales - timeout real
                        raise asyncio.TimeoutError(f"Failed to read response: {error_msg}")
                
                # Procesar respuesta
                if response == "OK":
                    # ‚úÖ Engine responde OK
                    if consecutive_failures > 0:
                        print(f"[MONITOR-{monitor_instance.cp_id}] ‚úÖ Recovered (was {consecutive_failures} failures)")
                        alert = monitor_instance.add_alert(
                            'success',
                            f"‚úÖ {monitor_instance.cp_id} recuperado tras {consecutive_failures} fallos"
                        )
                        await broadcast_alert(alert)
                    
                    consecutive_failures = 0
                    
                    shared_state.health_status = {
                        'consecutive_failures': 0,
                        'last_check': time.time(),
                        'last_status': 'OK'
                    }
                
                elif response == "KO":
                    # ‚ùå Engine responde KO
                    consecutive_failures += 1
                    print(f"[MONITOR-{monitor_instance.cp_id}] ‚ö†Ô∏è Health check KO (failure {consecutive_failures}/3)")
                    
                    shared_state.health_status = {
                        'consecutive_failures': consecutive_failures,
                        'last_check': time.time(),
                        'last_status': 'KO'
                    }
                    
                    # ‚úÖ Si 3+ fallos consecutivos, reportar a Central
                    if consecutive_failures >= 3:
                        # ‚ö†Ô∏è PROTECCI√ìN: No reportar el mismo fallo repetidamente (evitar bucle)
                        current_time = time.time()
                        if last_reported_failure and (current_time - last_reported_failure) < 60:  # No reportar m√°s de una vez por minuto
                            print(f"[MONITOR-{monitor_instance.cp_id}] ‚ö†Ô∏è Fallo ya reportado recientemente, esperando antes de reportar de nuevo")
                            consecutive_failures = 0  # Reset para evitar spam
                            await asyncio.sleep(2)
                            continue
                        
                        print(f"[MONITOR-{monitor_instance.cp_id}] üö® 3+ consecutive failures, reporting to Central")
                        
                        # A√±adir alerta cr√≠tica
                        alert = monitor_instance.add_alert(
                            'critical',
                            f"üî¥ {monitor_instance.cp_id} reporta 3+ fallos consecutivos (ENGINE_FAILURE)"
                        )
                        await broadcast_alert(alert)
                        
                        # Reportar a Central v√≠a Kafka
                        if monitor_instance.producer:
                            event = {
                                'message_id': generate_message_id(),
                                'event_type': 'ENGINE_FAILURE',
                                'action': 'report_engine_failure',
                                'cp_id': monitor_instance.cp_id,
                                'failure_type': 'ko',
                                'consecutive_failures': consecutive_failures,
                                'timestamp': current_timestamp(),
                                'monitor_id': f'MONITOR-{monitor_instance.cp_id}'
                            }
                            monitor_instance.producer.send(KAFKA_TOPIC_PRODUCE, event)
                            monitor_instance.producer.flush()
                            print(f"[MONITOR-{monitor_instance.cp_id}] üì§ ENGINE_FAILURE reported to Central")
                            last_reported_failure = current_time  # Marcar que se report√≥
                        
                        # Reset contador despu√©s de reportar
                        consecutive_failures = 0
                
                # Cerrar conexi√≥n de forma segura
                try:
                    writer.close()
                    await asyncio.wait_for(writer.wait_closed(), timeout=0.5)
                except Exception as close_error:
                    # Ignorar errores de cierre - el Engine ya puede haber cerrado la conexi√≥n
                    pass
                
            except asyncio.TimeoutError:
                # Timeout durante lectura de respuesta - considerar como fallo
                consecutive_failures += 1
                # Solo imprimir cada 3 fallos para reducir ruido
                if consecutive_failures % 3 == 0 or consecutive_failures <= 3:
                    print(f"[MONITOR-{monitor_instance.cp_id}] ‚ö†Ô∏è Timeout reading response (failure {consecutive_failures}/3)")
                
                shared_state.health_status = {
                    'consecutive_failures': consecutive_failures,
                    'last_check': time.time(),
                    'last_status': 'TIMEOUT'
                }
                
                if consecutive_failures >= 3:
                    # ‚ö†Ô∏è PROTECCI√ìN: No reportar fallos durante el per√≠odo de gracia inicial
                    time_since_start = time.time() - monitor_start_time
                    if time_since_start < startup_grace_period:
                        print(f"[MONITOR-{monitor_instance.cp_id}] ‚è≥ Monitor inici√≥ hace {time_since_start:.1f}s, esperando a que Engine est√© disponible (grace period: {startup_grace_period}s)")
                        consecutive_failures = 0  # Reset durante grace period
                        await asyncio.sleep(2)
                        continue
                    
                    # ‚ö†Ô∏è PROTECCI√ìN: No reportar el mismo fallo repetidamente (evitar bucle)
                    current_time = time.time()
                    if last_reported_failure and (current_time - last_reported_failure) < 60:  # No reportar m√°s de una vez por minuto
                        print(f"[MONITOR-{monitor_instance.cp_id}] ‚ö†Ô∏è Fallo ya reportado recientemente, esperando antes de reportar de nuevo")
                        consecutive_failures = 0  # Reset para evitar spam
                        await asyncio.sleep(5)
                        continue
                    
                    print(f"[MONITOR-{monitor_instance.cp_id}] üö® Connection timeouts, reporting to Central")
                    
                    alert = monitor_instance.add_alert(
                        'critical',
                        f"üî¥ {monitor_instance.cp_id} no responde (3+ timeouts)"
                    )
                    await broadcast_alert(alert)
                    
                    if monitor_instance.producer:
                        event = {
                            'message_id': generate_message_id(),
                            'event_type': 'ENGINE_FAILURE',
                            'action': 'report_engine_failure',
                            'cp_id': monitor_instance.cp_id,
                            'failure_type': 'timeout',
                            'consecutive_failures': consecutive_failures,
                            'timestamp': current_timestamp(),
                            'monitor_id': f'MONITOR-{monitor_instance.cp_id}'
                        }
                        monitor_instance.producer.send(KAFKA_TOPIC_PRODUCE, event)
                        monitor_instance.producer.flush()
                        last_reported_failure = current_time  # Marcar que se report√≥
                    
                    consecutive_failures = 0
            
            except (ConnectionRefusedError, OSError) as e:
                # Engine no est√° corriendo
                consecutive_failures += 1
                # Solo imprimir cada 3 fallos para reducir ruido
                if consecutive_failures % 3 == 0 or consecutive_failures <= 3:
                    print(f"[MONITOR-{monitor_instance.cp_id}] ‚ùå Cannot connect to Engine (failure {consecutive_failures}/3)")
                
                shared_state.health_status = {
                    'consecutive_failures': consecutive_failures,
                    'last_check': time.time(),
                    'last_status': 'CONNECTION_ERROR'
                }
                
                if consecutive_failures >= 3:
                    # ‚ö†Ô∏è PROTECCI√ìN: No reportar fallos durante el per√≠odo de gracia inicial (Engine puede estar iniciando)
                    time_since_start = time.time() - monitor_start_time
                    if time_since_start < startup_grace_period:
                        print(f"[MONITOR-{monitor_instance.cp_id}] ‚è≥ Monitor inici√≥ hace {time_since_start:.1f}s, esperando a que Engine est√© disponible (grace period: {startup_grace_period}s)")
                        consecutive_failures = 0  # Reset durante grace period
                        await asyncio.sleep(2)
                        continue
                    
                    # ‚ö†Ô∏è PROTECCI√ìN: No reportar el mismo fallo repetidamente (evitar bucle)
                    current_time = time.time()
                    if last_reported_failure and (current_time - last_reported_failure) < 60:  # No reportar m√°s de una vez por minuto
                        print(f"[MONITOR-{monitor_instance.cp_id}] ‚ö†Ô∏è Engine offline ya reportado recientemente, esperando antes de reportar de nuevo")
                        consecutive_failures = 0  # Reset para evitar spam
                        await asyncio.sleep(5)
                        continue
                    
                    print(f"[MONITOR-{monitor_instance.cp_id}] üö® Engine offline, reporting to Central")
                    
                    alert = monitor_instance.add_alert(
                        'critical',
                        f"üî¥ {monitor_instance.cp_id} - Engine offline"
                    )
                    await broadcast_alert(alert)
                    
                    if monitor_instance.producer:
                        event = {
                            'message_id': generate_message_id(),
                            'event_type': 'ENGINE_OFFLINE',
                            'action': 'report_engine_offline',
                            'cp_id': monitor_instance.cp_id,
                            'consecutive_failures': consecutive_failures,
                            'timestamp': current_timestamp(),
                            'monitor_id': f'MONITOR-{monitor_instance.cp_id}'
                        }
                        monitor_instance.producer.send(KAFKA_TOPIC_PRODUCE, event)
                        monitor_instance.producer.flush()
                        last_reported_failure = current_time  # Marcar que se report√≥
                    
                    consecutive_failures = 0
                    
                    # Esperar m√°s tiempo si no podemos conectar
                    await asyncio.sleep(5)
                    
        except asyncio.CancelledError:
            print(f"[MONITOR-{monitor_instance.cp_id}] üõë TCP health monitoring stopped")
            break
        except Exception as e:
            print(f"[MONITOR-{monitor_instance.cp_id}] ‚ùå Error in TCP health check: {e}")
            await asyncio.sleep(1)


async def main():
    """
    ============================================================================
    ARQUITECTURA CORRECTA: 1 Monitor por 1 Engine (1:1)
    ============================================================================
    Esta funci√≥n principal inicia los servicios para supervisar UN √öNICO Engine.
    ============================================================================
    """
    local_ip = get_local_ip()
    
    if not WS_AVAILABLE:
        print("‚ùå ERROR: WebSocket dependencies not installed")
        print("Run: pip install websockets aiohttp")
        return
    
    # Verificar base de datos (opcional, solo warning si no existe)
    db_path = Path('/app/ev_charging.db') if Path('/app/ev_charging.db').exists() else Path(__file__).parent.parent / 'ev_charging.db'
    if not db_path.exists():
        print("‚ö†Ô∏è  Database not found. Monitor will start anyway (read-only mode)")
    
    try:
        # Crear aplicaci√≥n web que maneje tanto HTTP como WebSocket
        app = web.Application()
        app.router.add_get('/', serve_dashboard)
        app.router.add_get('/ws', websocket_handler_http)
        
        # Iniciar servidor HTTP/WebSocket
        runner = web.AppRunner(app)
        await runner.setup()
        site = web.TCPSite(runner, '0.0.0.0', SERVER_PORT)
        await site.start()
        
        print(f"[HTTP] Dashboard server started on http://0.0.0.0:{SERVER_PORT}")
        print(f"[WS] WebSocket endpoint at ws://0.0.0.0:{SERVER_PORT}/ws")
        print(f"\n‚úÖ Access dashboard: http://localhost:{SERVER_PORT}")
        print(f"‚úÖ Access from network: http://{local_ip}:{SERVER_PORT}\n")
        
        # ========================================================================
        # ARQUITECTURA CORRECTA: Iniciar TCP health check para EL Engine asignado
        # ========================================================================
        print(f"[MONITOR-{monitor_instance.cp_id}] üè• Starting TCP health monitoring...")
        health_check_task = asyncio.create_task(tcp_health_check())
        
        # Iniciar broadcast de actualizaciones
        broadcast_task = asyncio.create_task(broadcast_updates())
        
        # Iniciar listener de Kafka para recibir actualizaciones en tiempo real
        kafka_task = asyncio.create_task(kafka_listener())
        
        print(f"\n‚úÖ All services started successfully!")
        print(f"üè• TCP monitoring active for {monitor_instance.cp_id}")
        print(f"üåê Engine at {monitor_instance.engine_host}:{monitor_instance.engine_port}")
        print(f"üì° Kafka listener active for real-time updates\n")
        
        # Mantener el servidor corriendo
        await asyncio.gather(broadcast_task, health_check_task, kafka_task)
        
    except Exception as e:
        print(f"\n‚ùå Error starting server: {e}")

if __name__ == "__main__":
    # ========================================================================
    # ARGUMENTOS DE L√çNEA DE COMANDOS
    # ========================================================================
    parser = argparse.ArgumentParser(
        description='EV Charging Point Monitor - Supervises ONE Engine (1:1)'
    )
    parser.add_argument(
        '--cp-id',
        required=True,
        help='ID del CP a monitorear (ej: CP_001)'
    )
    parser.add_argument(
        '--engine-host',
        default='localhost',
        help='Host del Engine (default: localhost)'
    )
    parser.add_argument(
        '--engine-port',
        type=int,
        required=True,
        help='Puerto TCP del Engine (ej: 5100)'
    )
    parser.add_argument(
        '--monitor-port',
        type=int,
        default=5500,
        help='Puerto para dashboard de este Monitor (default: 5500)'
    )
    parser.add_argument(
        '--kafka-broker',
        default=os.environ.get('KAFKA_BROKER', KAFKA_BROKER_DEFAULT),
        help='Kafka broker address (default: from config)'
    )
    
    args = parser.parse_args()
    
    # Actualizar variables globales (no necesita 'global' en el scope del m√≥dulo)
    MONITORED_CP_ID = args.cp_id
    ENGINE_HOST = args.engine_host
    ENGINE_PORT = args.engine_port
    SERVER_PORT = args.monitor_port
    
    # ========================================================================
    # CREAR INSTANCIA DEL MONITOR (1:1 con Engine)
    # ========================================================================
    monitor_instance = EV_MonitorWS(
        cp_id=args.cp_id,
        engine_host=args.engine_host,
        engine_port=args.engine_port,
        kafka_broker=args.kafka_broker
    )
    
    # Iniciar servidor
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print(f"\n\n[MONITOR-{args.cp_id}] üõë Server stopped by user")
    except Exception as e:
        print(f"\n‚ùå Fatal error: {e}")
        import traceback
        traceback.print_exc()
